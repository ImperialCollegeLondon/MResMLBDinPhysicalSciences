{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d07e58",
   "metadata": {},
   "source": [
    "# MLBD Pre-course Material\n",
    "\n",
    "## Statistics in Python\n",
    "\n",
    "In the MLBD MRes taught module \"Statistical Methods for Experimental Physics\n",
    "\", we use python heavily. In this precourse material, we will introduce the basic tools in python that we use for statistics. Some of these are also covered in the \"Scientific Python\" precourse, but here we'll focus on statistics use cases.\n",
    "\n",
    "The most common packages we'll need are `matplotlib`, `numpy` and `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9106e77",
   "metadata": {},
   "source": [
    "## Random variables\n",
    "\n",
    "Random variables are a central concept in probability and statistics. We will only deal with two types of random variables, discrete and continuous. \n",
    "\n",
    "In python, we can use the `numpy.random` variable for generating random discrete and continuous variables. \n",
    "\n",
    "for *discrete* variables, we might have a set (or infinite set) of discrete outcomes for some event. For example, the event could be a dice roll, where the discrete outcomes are 1,2,3,4,5 or 6. We can randomly generate rolls using the `numpy.random.choice` method.\n",
    "\n",
    "Each time you run the cell below, you will see a different random outcome and the probability for any outcome will be equal.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a4459",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_roll_outcomes = ['1','2','3','4','5','6']\n",
    "random_roll = numpy.random.choice(dice_roll_outcomes)\n",
    "print(random_roll)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3fbdc4",
   "metadata": {},
   "source": [
    "We can also generate random *continuous* variables using python with the `numpy.random.uniform` method. By default, this will generate a random number  between  0 and 1, but we can also provide a minimum and maximum value to change that range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum=-1\n",
    "maximum=3\n",
    "random_continuous = numpy.random.uniform(minimum,maximum)\n",
    "print(random_continuous)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0838a65d",
   "metadata": {},
   "source": [
    "## Probability distributions\n",
    "\n",
    "In the above cells, the probability that a particular outcome occurs is independent on that outcome. We also want to look at random variables that are distributed such that different outcomes have different probabilities  -- i.e we want to use probability distributions. \n",
    "\n",
    "the `scipy.stats` package has lots of different probability  distributions  we can access. Below are some examples of common probability distributions. We'll use the notation  that $x$ is our random variable and $f(x;\\theta)$ is the probability distribution, where $\\theta$ are the parameters of that distribution.  \n",
    "\n",
    "Let's take for example the *Poisson*  distribution, which has one parameter $\\lambda$. \n",
    "\n",
    "$$\n",
    "f(x;\\lambda) = \\frac{\\lambda^{x}}{x!}e^{-\\lambda}\n",
    "$$\n",
    "\n",
    "The Poisson distribution is for discrete random variables and $x$ will be a random integer between 0 and +infinity. In scipy we can use the `stats.poisson` module. \n",
    "\n",
    "We can plot the distribution using  the `.pmf` (for discrete random variables) which stands for \"probability mass function\". Note that the `pmf` function has the calling pattern `.pmf(x,param1,param2,...)`.\n",
    "\n",
    "Try changing the value of $\\lambda$ (called `lamb`) to see how the distribution changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0ec74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lamb = 5\n",
    "x = range(0,20) \n",
    "\n",
    "plt.plot(x,stats.poisson.pmf(x,lamb),marker=\"o\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$f(x;\\lambda)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e33c3e",
   "metadata": {},
   "source": [
    "**Q: In the code block below, plot the Poisson probability distribution for several values of the lambda parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try lamb = 2, 8, 10 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df7d6e",
   "metadata": {},
   "source": [
    "We can do the same thing for continuous random  variables. For example, the Gaussian distribution has two parameters $\\mu$, and $\\sigma$. The probability density is given by, \n",
    "\n",
    "$$\n",
    "f(X;\\mu,\\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{X-\\mu}{\\sigma}\\right)^{2}}\n",
    "$$\n",
    "\n",
    "In scipy, a Gaussian is called a *normal* distribution (`stats.norm`) \n",
    "\n",
    "In this case we need to use the `.pdf` function - which stands for \"probability density function\" to plot the distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3299850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 10\n",
    "sigma = 3\n",
    "x = range(0,20)\n",
    "\n",
    "plt.plot(x,stats.norm.pdf(x,mu,sigma))\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$f(x;\\lambda)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4665a",
   "metadata": {},
   "source": [
    "**Q: In the code block below, plot the Gaussian (or normal) probability distribution for several values of the mu and sigma parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2045ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try mu = 5, 15 ; sigma = 2, 1, 10 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291d779",
   "metadata": {},
   "source": [
    "We  can use these modules to *generate* random variables that are distributed according to some probability distribution. For example, lets generate 100 discrete random variables that are distributed according to a **Poisson** distribution with parameter $\\lambda=4$. We will use the `.rvs` method for it. \n",
    "\n",
    "Note that the calling pattern is `.rvs(param1,param2,...,size=n)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce61e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_random = stats.poisson.rvs(4,size=100)\n",
    "print(discrete_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19569c8a",
   "metadata": {},
   "source": [
    "We can plot these as a *histogram* to see how the random variables are distributed using matplotlib `hist`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb3bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(discrete_random,bins=10,range=(0.5,10.5))\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"number of occurances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e59c5e4",
   "metadata": {},
   "source": [
    "We can also draw the probability distribution on top of the histogram and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6407d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(discrete_random,bins=10,range=(0.5,10.5))\n",
    "plt.plot(x,stats.poisson.pmf(x,4))\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"number of occurances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534bc01b",
   "metadata": {},
   "source": [
    "Notice how the line is very small on the graph. This is because the default behaviour of `hist` is to just fill each bin with the number of events landing in that bin. Clearly the normalisation will be the total number of generated events (100), so to compare properly, we need to draw the histogram as a *density* so that its normalisation is equal to 1. Thankfully, there is an option to do this for us `density=True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45367509",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(discrete_random,bins=10,range=(0.5,10.5),density=True)\n",
    "plt.plot(x,stats.poisson.pmf(x,4))\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"number of occurances\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37435977",
   "metadata": {},
   "source": [
    "**Q: Have a go at generating more than 100 Poisson random variables and comparing the resulting density histogram with the probability density. What do you notice as the number increases?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f46644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739d242",
   "metadata": {},
   "source": [
    "**Q: Have a go at generating a Gaussian random variable. You can find a list of the probabillity distributions available in `scipy.stats` at** https://docs.scipy.org/doc/scipy/reference/tutorial/stats/discrete.html **and** https://docs.scipy.org/doc/scipy/reference/tutorial/stats/continuous.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f25e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Gaussian random numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc259cf",
   "metadata": {},
   "source": [
    "## Moments\n",
    "\n",
    "We often want to calculate moments of distributions of samples of random variables. In python, we can do this very quickly using the `numpy` package. \n",
    "\n",
    "Let's calculate the mean and standard deviation for a sample of random numbers that are generated from a Gaussian distribution with parameters $\\mu=0$,$\\sigma=4$. \n",
    "\n",
    "The mean is calculated as \n",
    "$$\n",
    "    \\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_{i}\n",
    "$$\n",
    "\n",
    "and the standard deviation is calculated as \n",
    "$$\n",
    "    \\sigma(X) = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} \\left(X_{i}-\\bar{X}\\right)^{2}}\n",
    "$$\n",
    "\n",
    "We can use the built-in functions from `numpy` to calculate these for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_variables = stats.norm.rvs(0,4,1000)\n",
    "\n",
    "print(\"mean=\",numpy.mean(random_variables))\n",
    "print(\"standard deviation=\",numpy.std(random_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8eba9f",
   "metadata": {},
   "source": [
    "You will see that the mean is quite close to $\\mu$ and  the standard deviation is close to $\\sigma$. There is a good reason for this that you'll learn in your statistics lectures!\n",
    "\n",
    "**Q: In the code block below, write the functions for the mean and standard deviation, and compare them to the results from the built-in** `numpy` **functions. Do you see any differences in the results or the time taken to calculate them?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c3ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
